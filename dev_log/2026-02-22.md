# Dev Log — 2026-02-22

## Summary

Full implementation of the Anything Extractor system from scratch. Went from empty directory to working end-to-end pipeline in a single session.

---

## What Was Done

### 1. Project Setup

- Created project structure: `src/ae/`, `workflows/`, `data/`, `migrations/`, `tests/`, `logs/`
- Wrote `pyproject.toml` with all dependencies (typer, openai, sqlalchemy, alembic, pymupdf, pydantic, rich, gitpython, etc.)
- Configured `.env` with SiliconFlow API keys, model assignments, database URL
- Installed package in editable mode (`pip install -e .`)

### 2. Foundation Layer (~900 lines)

| File | Lines | Description |
|------|-------|-------------|
| `config.py` | 80 | Pydantic Settings — reads `.env`, exposes typed config |
| `db.py` | 102 | SQLAlchemy engine/session — SQLite default with WAL mode, optional PostgreSQL |
| `models.py` | 275 | 10 ORM models: Task, Document, SchemaVersion, WorkflowVersion, Extraction, ObserverJudgment, FeedbackRecord, EvolutionEvent, SharedPattern, CornerCase |
| `llm.py` | 216 | SiliconFlow client — `chat()`, `chat_json()`, `chat_vision()` with robust JSON parsing |
| `pdf.py` | 234 | PDF parsing — pymupdf + MinerU API fallback, filename metadata extraction for Chinese reports |

### 3. Shared Modules (~900 lines)

| File | Lines | Description |
|------|-------|-------------|
| `shared/types.py` | 144 | WorkflowContext, ExtractionResult, protocols, enums |
| `shared/prompts.py` | 631 | 7 bilingual prompt templates (EN/ZH/bilingual) for Builder, Worker, Observer |
| `shared/utils.py` | 111 | Code validation (AST), JSON parsing, text truncation, PDF file collection |

### 4. Builder Subsystem (~1,040 lines)

| File | Lines | Description |
|------|-------|-------------|
| `builder/bootstrap.py` | 330 | Full bootstrap pipeline: ingest → analyze → schema → workflow → git commit |
| `builder/codegen.py` | 227 | LLM-powered code generation with AST validation and retry |
| `builder/analyzer.py` | 151 | Issue diagnosis: systemic vs corner-case classification |
| `builder/git_ops.py` | 133 | GitPython operations: init repo, commit workflow, diff, list versions |
| `builder/pattern_lib.py` | 112 | Shared pattern library with confidence tracking |
| `builder/schema_mgr.py` | 89 | Schema versioning: create, activate/deactivate, history, diff |

### 5. Worker Subsystem (~490 lines)

| File | Lines | Description |
|------|-------|-------------|
| `worker/runner.py` | 201 | Dynamic module loading (importlib), WorkflowContext construction, batch extraction |
| `worker/confidence.py` | 101 | Composite confidence scoring (5 weighted components) |
| `worker/postprocess.py` | 188 | JSON + Excel export with color-coded confidence sheets |

### 6. Observer Subsystem (~575 lines)

| File | Lines | Description |
|------|-------|-------------|
| `observer/judge.py` | 245 | LLM-as-Judge: text-only and vision-based evaluation |
| `observer/sampler.py` | 68 | Adaptive sampling: 100% → 50% → 20% → 5% over iterations |
| `observer/trigger.py` | 124 | Quality threshold detection, per-field metrics computation |
| `observer/feedback.py` | 137 | Interactive CLI for human corrections (approve/correct/reject) |

### 7. CLI (~610 lines)

- `cli.py` — 11 commands: `new`, `run`, `status`, `observe`, `feedback`, `evolve`, `export`, `schema`, `history`, `workflow`, `patterns`
- Rich tables for status display, progress bars for batch operations

### 8. Alembic Migrations

- `alembic.ini` configured
- `migrations/env.py` wired to ae.config and ae.models
- `migrations/versions/001_initial.py` — creates all 10 tables

---

## End-to-End Testing

### Bootstrap Test

```
ae new "从这些研报中提取有用的信息" --input ./corpus_research_report_202602/2026-02-06 --samples 3
```

**Result**:
- 100 PDFs ingested from 2026-02-06 folder
- 3 marked as samples for analysis
- Builder (GLM-5) analyzed documents, identified them as "Investment Research Reports & Industry White Papers"
- Auto-proposed 10-field schema: broker_institution, report_title, publication_date, analyst_author, disclaimer, report_category, core_viewpoints, market_data, key_news_items, mentioned_companies
- Generated workflow v1 (Python code), git committed as `51ce4830`

### Extraction Test

Ran on 3 documents. All succeeded:
- **ABB白皮书**: Extracted broker (ABB中国), title, category, core viewpoints, mentioned companies (Metsä Group, Sappi, etc.)
- **Raptor-Maps报告**: Extracted broker, title, core viewpoints about solar robots, mentioned companies
- **万联证券晨会**: Extracted full market data (上证指数 4075.92 -0.64%, 深证成指 13952.71 -1.44%, etc.), key news items, disclaimer

### Observer Test

LLM-as-Judge evaluated all 3 extractions:
- Average score: **0.72** (partial quality)
- Per-field accuracy: broker_institution 100%, report_title 100%, analyst_author 33%, publication_date 33%
- Correctly identified that publication_date from filename was unreliable

### Evolution Test

```
ae evolve 从这些研报中提取有用的信息
```

**Result**:
- Builder diagnosed **systemic issue**: publication_date from filename metadata was being used with 0.95 confidence but was actually a processing timestamp, not the report date
- Generated workflow v2 with fixes:
  - Removed publication_date from filename extraction
  - Always extracts date via LLM
  - Improved analyst_author handling (fallback to institution name for white papers)
  - Better disclaimer detection patterns
- Git committed as `dd70986f`
- Re-ran extraction on 3 documents with v2
- Re-observed with adaptive sampling (50% at iteration 1)

### Export Test

- `ae export --format json` → `data/output/从这些研报中提取有用的信息_results.json`
- `ae export --format excel` → `data/output/从这些研报中提取有用的信息_results.xlsx`

Both generated successfully with Chinese content rendered correctly.

---

## Bugs Found & Fixed

### 1. Model name mismatch
- **Issue**: `.env` had `AE_BUILDER_MODEL=Pro/THUDM/GLM-4-Plus` but SiliconFlow API returned "Model does not exist"
- **Fix**: Queried SiliconFlow model list, corrected to `Pro/zai-org/GLM-5`
- **Also fixed**: Worker model tiers updated from Qwen2.5 to Qwen3 series

### 2. Vision image path error (ENAMETOOLONG)
- **Issue**: `chat_vision()` checked `Path(img).exists()` before checking if the string was a `data:` URI, causing a "File name too long" error on base64 data
- **Fix**: Reordered checks — test for `data:` prefix first, then try as file path

### 3. LLM JSON parsing with markdown fences
- **Issue**: GLM-5 sometimes wraps JSON responses in `` ```json ... ``` `` fences, causing `json.loads()` to fail
- **Fix**: Added `_parse_json_response()` helper that strips markdown fences, tries direct parse, then extracts JSON objects/arrays from text

### 4. Generated workflow API mismatch
- **Issue**: Builder-generated workflow v1 called `context.llm.chat_json(prompt_string, model=...)` but the actual API takes `messages=[...]`
- **Fix**: Manually corrected extract_v1.py to use proper `messages` format. This is expected — the Builder's generated code sometimes needs a validation/correction pass. Future improvement: add runtime contract testing.

### 5. pyproject.toml build backend
- **Issue**: Used `setuptools.backends._legacy:_Backend` which doesn't exist
- **Fix**: Changed to `setuptools.build_meta`

---

## Metrics

| Metric | Value |
|--------|-------|
| Total Python code | ~4,700 lines across 22 modules |
| Bootstrap time | ~3 minutes (100 PDF parse + 3 LLM calls) |
| Extraction time (3 docs) | ~2 minutes (6 LLM calls, 9,038 tokens) |
| Observer time (3 docs) | ~2 minutes (3 LLM calls) |
| Evolution cycle | ~5 minutes (diagnose + codegen + re-extract + re-observe) |

---

## Next Steps

- [ ] Run full extraction on all 100 documents
- [ ] Run multiple evolution iterations to test model downgrading
- [ ] Test code migration (LLM → regex for deterministic fields like dates, broker names)
- [ ] Test multi-task scenario with shared pattern propagation
- [ ] Add runtime contract testing for Builder-generated workflows
- [ ] Performance optimization: batch LLM calls, async extraction
- [ ] Test PostgreSQL + Redis deployment
- [ ] Add unit tests
